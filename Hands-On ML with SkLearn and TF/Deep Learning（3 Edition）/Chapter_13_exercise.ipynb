{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ba7bcea",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cddb880",
   "metadata": {},
   "source": [
    "您为什么要使用tf.data API？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdd71c9",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "获取大型数据集并对其进行高效预处理可能是一项复杂的工程挑战。 数据 API 使它变得相当简单。 它提供了许多功能，包括从各种来源（如文本或二进制文件）加载数据、从多个来源并行读取数据、转换数据、交错记录、打乱数据、批处理和预取数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233c7cb",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b1e14b",
   "metadata": {},
   "source": [
    "将一个大的数据集分割成多个文件的好处是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c937ddc",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "将大型数据集拆分为多个文件，可以在使用混洗缓冲区将其混洗到更精细的水平之前，先对其进行粗略的洗牌。 它还可以处理单台机器无法容纳的庞大数据集。 操作数以千计的小文件也比操作一个大文件更简单； 例如，将数据拆分为多个子集会更容易。 最后，如果数据被拆分到分布在多个服务器上的多个文件中，则可以同时从不同的服务器下载多个文件，从而提高带宽使用率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f4d00",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409631e",
   "metadata": {},
   "source": [
    "在训练期间，如何判断输入pipeline是瓶颈？你能做些什么来解决它呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85debfe",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "您可以使用 TensorBoard 可视化分析数据：如果 GPU 没有得到充分利用，那么您的输入管道很可能成为瓶颈。 \n",
    "\n",
    "您可以通过确保它在多个线程中并行读取和预处理数据并确保它预取几个批次来修复它。 如果这不足以让您的 GPU 在训练期间达到 100% 使用率，请确保您的预处理代码已优化。 您还可以尝试将数据集保存到多个 TFRecord 文件中，并在必要时提前执行一些预处理，这样就不需要在训练期间即时完成（TF Transform 可以帮助实现这一点）。 如有必要，请使用具有更多 CPU 和 RAM 的机器，并确保 GPU 带宽足够大。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf9ff63",
   "metadata": {},
   "source": [
    "## Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5db0aa8",
   "metadata": {},
   "source": [
    "是否可以将任何二进制数据保存到TFRecord文件，还是只保存序列化的协议缓冲区？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc7f6b",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "TFRecord 文件由一系列任意二进制记录组成：您可以在每条记录中存储您想要的任何二进制数据。 但是，实际上大多数 TFRecord 文件都包含序列化协议缓冲区序列。 这使得受益于协议缓冲区的优势成为可能，例如它们可以跨多种平台和语言轻松读取，并且它们的定义可以在以后以向后兼容的方式更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d73ada",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c800a0c",
   "metadata": {},
   "source": [
    "为什么要将所有数据转换为 Example protobuf 格式？为什么不使用你自己的 protobuf 定义呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb10e40",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "Example protobuf 格式的优点是 TensorFlow 提供了一些操作来解析它（tf.io.parse\\*example() 函数），而您无需定义自己的格式。 它足够灵活，可以表示大多数数据集中的实例。 \n",
    "\n",
    "但是，如果它不涵盖您的用例，您可以定义自己的协议缓冲区，使用 protoc 编译它（设置 --descriptor_set_out 和 --include_imports 参数以导出 protobuf 描述符），并使用 tf.io.decode_proto( ) 函数来解析序列化的 protobuf（有关示例，请参见笔记本的“自定义 protobuf”部分）。 它更复杂，需要将描述符与模型一起部署，但可以做到。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc988184",
   "metadata": {},
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd14a5b",
   "metadata": {},
   "source": [
    "使用 TFRecords 时，什么时候激活压缩？为什么不系统地这样做呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ad776",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "使用 TFRecord 时，如果训练脚本需要下载 TFRecord 文件，您通常会希望激活压缩，因为压缩会使文件变小，从而减少下载时间。 但是，如果文件与训练脚本位于同一台机器上，通常最好关闭压缩，以避免浪费 CPU 进行解压缩。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41059243",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369687f7",
   "metadata": {},
   "source": [
    "数据可以在写入数据文件时直接进行预处理，或者在 tf.data pipeline 中进行，或在模型中的预处理层中进行。你能列出每种选择的一些优缺点吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97639347",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "让我们看看每个预处理选项的优缺点：\n",
    "\n",
    "1. 如果您在创建数据文件时对数据进行预处理，训练脚本将运行得更快，因为它不必即时执行预处理。 在某些情况下，预处理后的数据也会比原始数据小很多，这样可以节省一些空间并加快下载速度。 将预处理后的数据具体化也可能会有帮助，例如检查它或将其存档。 但是，这种方法有一些缺点。 首先，如果您需要为每个变体生成预处理数据集，那么尝试各种预处理逻辑并不容易。 其次，如果要进行数据扩充，则必须具体化数据集的许多变体，这将占用大量磁盘空间并花费大量时间来生成。 最后，经过训练的模型需要预处理数据，因此您必须在应用程序调用模型之前在应用程序中添加预处理代码。 在这种情况下，存在代码重复和预处理不匹配的风险。\n",
    "2. 如果使用 tf.data pipeline 对数据进行预处理，则调整预处理逻辑和应用数据扩充会容易得多。 此外，tf.data 可以轻松构建高效的预处理管道（例如，使用多线程和预取）。 但是，以这种方式预处理数据会减慢训练速度。 此外，如果在创建数据文件时对数据进行了预处理，则每个训练实例将在每个时期预处理一次，而不是仅预处理一次。 好吧，除非数据集适合 RAM，并且您可以使用数据集的 cache() 方法缓存它。 最后，经过训练的模型仍将需要预处理数据。 但是，如果您在 tf.data 管道中使用预处理层来处理预处理步骤，那么您可以在最终模型中重复使用这些层（在训练后添加它们），以避免代码重复和预处理不匹配。\n",
    "3. 如果将预处理层添加到模型中，则只需为训练和推理编写一次预处理代码。 如果您的模型需要部署到许多不同的平台，您将不需要多次编写预处理代码。 另外，您不会冒为模型使用错误预处理逻辑的风险，因为它将成为模型的一部分。 不利的一面是，在训练期间即时预处理数据会减慢速度，并且每个实例每个时期都会预处理一次。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e427e4ca",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbde62a",
   "metadata": {},
   "source": [
    "列举几种编码分类整数特征的常见方法。关于文本呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1d236",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "让我们看看如何对分类文本特征和文本进行编码：\n",
    "\n",
    "1. 要对具有自然顺序的分类特征进行编码，例如电影评级（例如，“差”、“一般”、“好”），最简单的选择是使用序号编码：按自然顺序对类别进行排序并映射 每个类别与其排名（例如，“坏”映射到 0，“平均”映射到 1，“好”映射到 2）。 然而，大多数分类特征都没有这样的自然顺序。 例如，职业或国家没有自然秩序。 在这种情况下，您可以使用 one-hot encoding，如果类别很多，则可以使用 embeddings。 使用 Keras，StringLookup 层可用于顺序编码（使用默认的 output_mode=\"int\"），或独热编码（使用 output_mode=\"one_hot\"）。 如果您想将多个分类文本特征一起编码，它还可以执行多热编码（使用 output_mode=\"multi_hot\"），假设它们共享相同的类别并且哪个特征贡献哪个类别并不重要。 对于可训练的嵌入，您必须首先使用 StringLookup 层生成序号编码，然后使用嵌入层。\n",
    "2. 对于文本，TextVectorization 层易于使用，可以很好地完成简单的任务，或者您可以使用 TF Text 来实现更高级的功能。 但是，您通常会希望使用预训练语言模型，您可以使用 TF Hub 或 Hugging Face 的 Transformers 库等工具获得这些模型。 最后两个选项将在第 16 章中讨论。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe5ea0d",
   "metadata": {},
   "source": [
    "## Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d174674",
   "metadata": {},
   "source": [
    "加载 Fashion MNIST 数据集（在第 10 章中介绍）； 将其拆分为训练集、验证集和测试集； 洗牌训练集； 并将每个数据集保存到多个 TFRecord 文件中。 每条记录应该是一个序列化的 Example protobuf，具有两个特征：序列化图像（使用 tf.io.serialize_tensor() 序列化每个图像）和标签。然后使用 tf.data 为每个集合创建一个高效的数据集。 最后，使用 Keras 模型训练这些数据集，包括一个预处理层来标准化每个输入特征。 尝试使输入管道尽可能高效，使用 TensorBoard 可视化分析数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac554bdc",
   "metadata": {},
   "source": [
    "**答案**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262e7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "import tensorboard\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "288bbf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f7739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_set = train_set.shuffle(len(X_train), seed=42)\n",
    "\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "282532c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    #image_data = tf.io.encode_jpeg(image[..., np.newaxis])\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\": Feature(bytes_list=BytesList(value=[image_data.numpy()])),\n",
    "                \"label\": Feature(int64_list=Int64List(value=[label])),\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cfdd99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e983fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "             for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                   for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0ff16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd0a2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    #image = tf.io.decode_jpeg(example[\"image\"])\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                  n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths,\n",
    "                                      num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539fe11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "\n",
    "valid_set = mnist_dataset(valid_filepaths)\n",
    "\n",
    "test_set = mnist_dataset(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba72eceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d52213f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "standardization = tf.keras.layers.Normalization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label: image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    standardization,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce1df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.4464 - accuracy: 0.8400 - val_loss: 0.3590 - val_accuracy: 0.8698\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3330 - accuracy: 0.8783 - val_loss: 0.3364 - val_accuracy: 0.8784\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2969 - accuracy: 0.8897 - val_loss: 0.3215 - val_accuracy: 0.8836\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2715 - accuracy: 0.8983 - val_loss: 0.3219 - val_accuracy: 0.8858\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2528 - accuracy: 0.9052 - val_loss: 0.3370 - val_accuracy: 0.8798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294fa6525e0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "logs = Path() / \"my_logs\" / \"run_\" / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=logs, histogram_freq=1, profile_batch=10)\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set,\n",
    "          callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "050a1745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-53e180412ca24f94\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-53e180412ca24f94\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868839ce",
   "metadata": {},
   "source": [
    "## Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef0cf1",
   "metadata": {},
   "source": [
    "在本练习中，您将下载一个数据集，分割它，创建一个tf.data.Dataset，以有效地加载和预处理，然后构建并训练包含嵌入层的二分类模型：\n",
    "\n",
    "1. 下载大型电影评论数据集，其中包含来自互联网电影数据库 (IMDb) 的 50,000 条电影评论。 数据被组织在两个目录中，train 和 test，每个目录包含一个包含 12,500 个正面评论的 pos 子目录和一个包含 12,500 个负面评论的 neg 子目录。 每条评论都存储在一个单独的文本文件中。 还有其他文件和文件夹（包括预处理的词袋版本），但我们将在本练习中忽略它们。\n",
    "2. 将测试集拆分为验证集（15000）和测试集（10000）。\n",
    "3. 使用tf.data为每个数据集创建一个有效的数据集。\n",
    "4. 创建一个二分类模型，使用文本向量化层来对每个评论进行预处理。\n",
    "5. 添加一个嵌入层，并计算每个评价的平均嵌入，再乘以单词数的平方根（见第16章）。这个重新缩放的平均嵌入可以传递到模型的其余部分。\n",
    "6. 训练模型，看看你能得到什么样的准确性。试着优化你的pipeline，使训练尽可能快。\n",
    "7. 使用TFDS可以更容易地加载相同的数据集：tfds.load（“imdb_reviews”）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c113bb6",
   "metadata": {},
   "source": [
    "**答案**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e85ae0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84125825/84125825 [==============================] - 15s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('datasets/aclImdb')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "root = \"https://ai.stanford.edu/~amaas/data/sentiment/\"\n",
    "filename = \"aclImdb_v1.tar.gz\"\n",
    "\n",
    "filepath = tf.keras.utils.get_file(filename, root + filename, extract=True,\n",
    "                                   cache_dir=\".\")\n",
    "\n",
    "path = Path(filepath).with_name(\"aclImdb\")\n",
    "\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f31abb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the structure of the aclImdb directory\n",
    "\n",
    "def tree(path, level=0, indent=4, max_files=3):\n",
    "    if level == 0:\n",
    "        print(f\"{path}/\")\n",
    "        level += 1\n",
    "    sub_paths = sorted(path.iterdir())\n",
    "    sub_dirs = [sub_path for sub_path in sub_paths if sub_path.is_dir()]\n",
    "    filepaths = [sub_path for sub_path in sub_paths if not sub_path in sub_dirs]\n",
    "    indent_str = \" \" * indent * level\n",
    "    for sub_dir in sub_dirs:\n",
    "        print(f\"{indent_str}{sub_dir.name}/\")\n",
    "        tree(sub_dir,  level + 1, indent)\n",
    "    for filepath in filepaths[:max_files]:\n",
    "        print(f\"{indent_str}{filepath.name}\")\n",
    "    if len(filepaths) > max_files:\n",
    "        print(f\"{indent_str}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ab5907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\aclImdb/\n",
      "    test/\n",
      "        neg/\n",
      "            0_2.txt\n",
      "            10000_4.txt\n",
      "            10001_1.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_10.txt\n",
      "            10000_7.txt\n",
      "            10001_9.txt\n",
      "            ...\n",
      "        labeledBow.feat\n",
      "        urls_neg.txt\n",
      "        urls_pos.txt\n",
      "    train/\n",
      "        neg/\n",
      "            0_3.txt\n",
      "            10000_4.txt\n",
      "            10001_4.txt\n",
      "            ...\n",
      "        pos/\n",
      "            0_9.txt\n",
      "            10000_8.txt\n",
      "            10001_10.txt\n",
      "            ...\n",
      "        unsup/\n",
      "            0_0.txt\n",
      "            10000_0.txt\n",
      "            10001_0.txt\n",
      "            ...\n",
      "        labeledBow.feat\n",
      "        unsupBow.feat\n",
      "        urls_neg.txt\n",
      "        ...\n",
      "    imdb.vocab\n",
      "    imdbEr.txt\n",
      "    README\n"
     ]
    }
   ],
   "source": [
    "tree(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187ac48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500, 12500, 12500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def review_paths(dirpath):\n",
    "    return [str(path) for path in dirpath.glob(\"*.txt\")]\n",
    "\n",
    "train_pos = review_paths(path / \"train\" / \"pos\")\n",
    "train_neg = review_paths(path / \"train\" / \"neg\")\n",
    "test_valid_pos = review_paths(path / \"test\" / \"pos\")\n",
    "test_valid_neg = review_paths(path / \"test\" / \"neg\")\n",
    "\n",
    "len(train_pos), len(train_neg), len(test_valid_pos), len(test_valid_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7105a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test set into a validation set (15,000) and a test set (10,000).\n",
    "\n",
    "np.random.shuffle(test_valid_pos)\n",
    "\n",
    "test_pos = test_valid_pos[:5000]\n",
    "test_neg = test_valid_neg[:5000]\n",
    "valid_pos = test_valid_pos[5000:]\n",
    "valid_neg = test_valid_neg[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a67de18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use tf.data to create an efficient dataset for each set\n",
    "\n",
    "# Since the dataset fits in memory\n",
    "# we can just load all the data using pure Python code \n",
    "# and use tf.data.Dataset.from_tensor_slices()\n",
    "\n",
    "def imdb_dataset(filepaths_positive, filepaths_negative):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for filepaths, label in ((filepaths_negative, 0), (filepaths_positive, 1)):\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath,encoding='utf-8') as review_file:\n",
    "                reviews.append(review_file.read())\n",
    "            labels.append(label)\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (tf.constant(reviews), tf.constant(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "890fe9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n",
      "tf.Tensor(b\"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X, y in imdb_dataset(train_pos, train_neg).take(3):\n",
    "    print(X)\n",
    "    print(y)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08a0d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.2 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass\n",
    "\n",
    "# It takes about 17 seconds to load the dataset and go through it 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75ba8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But let's pretend the dataset does not fit in memory\n",
    "# just to make things more interesting\n",
    "# Luckily, each review fits on just one line (they use <br /> to indicate line breaks)\n",
    "# so we can read the reviews using a TextLineDataset. \n",
    "# If they didn't we would have to preprocess the input files (e.g., converting them to TFRecords). \n",
    "# For very large datasets, it would make sense to use a tool like Apache Beam for that.\n",
    "\n",
    "def imdb_dataset(filepaths_positive, filepaths_negative, n_read_threads=5):\n",
    "    dataset_neg = tf.data.TextLineDataset(filepaths_negative,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_neg = dataset_neg.map(lambda review: (review, 0))\n",
    "    dataset_pos = tf.data.TextLineDataset(filepaths_positive,\n",
    "                                          num_parallel_reads=n_read_threads)\n",
    "    dataset_pos = dataset_pos.map(lambda review: (review, 1))\n",
    "    return tf.data.Dataset.concatenate(dataset_pos, dataset_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78027187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f9d95d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.3 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -r1 for X, y in imdb_dataset(train_pos, train_neg).cache().repeat(10): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93a0e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = imdb_dataset(train_pos, train_neg).shuffle(25000, seed=42)\n",
    "train_set = train_set.batch(batch_size).prefetch(1)\n",
    "\n",
    "valid_set = imdb_dataset(valid_pos, valid_neg).batch(batch_size).prefetch(1)\n",
    "test_set = imdb_dataset(test_pos, test_neg).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c28cce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a binary classification model\n",
    "# using a TextVectorization layer to preprocess each review\n",
    "\n",
    "max_tokens = 1000\n",
    "sample_reviews = train_set.map(lambda review, label: review)\n",
    "\n",
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens, output_mode=\"tf_idf\")\n",
    "\n",
    "text_vectorization.adapt(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "386f1327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's take a look at the first 10 words in the vocabulary\n",
    "# These are the most common words in the reviews\n",
    "\n",
    "text_vectorization.get_vocabulary()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e1ced02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 8s 7ms/step - loss: 0.4528 - accuracy: 0.8192 - val_loss: 0.4922 - val_accuracy: 0.8086\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.3656 - accuracy: 0.8542 - val_loss: 0.3572 - val_accuracy: 0.8497\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.3094 - accuracy: 0.8725 - val_loss: 0.4393 - val_accuracy: 0.8190\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 7s 7ms/step - loss: 0.2499 - accuracy: 0.9001 - val_loss: 0.3798 - val_accuracy: 0.8487\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 7s 6ms/step - loss: 0.1869 - accuracy: 0.9262 - val_loss: 0.4470 - val_accuracy: 0.8381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29482531460>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    text_vectorization,\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65905073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[3.535534 , 4.9497476, 2.1213205],\n",
       "       [6.       , 0.       , 0.       ]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an Embedding layer \n",
    "# compute the mean embedding for each review, multiplied by the square root of the number of words (see Chapter 16). \n",
    "# This rescaled mean embedding can then be passed to the rest of your model.\n",
    "\n",
    "def compute_mean_embedding(inputs):\n",
    "    not_pad = tf.math.count_nonzero(inputs, axis=-1)\n",
    "    n_words = tf.math.count_nonzero(not_pad, axis=-1, keepdims=True)    \n",
    "    sqrt_n_words = tf.math.sqrt(tf.cast(n_words, tf.float32))\n",
    "    return tf.reduce_sum(inputs, axis=1) / sqrt_n_words\n",
    "\n",
    "another_example = tf.constant([[[1., 2., 3.], [4., 5., 0.], [0., 0., 0.]],\n",
    "                               [[6., 0., 0.], [0., 0., 0.], [0., 0., 0.]]])\n",
    "\n",
    "compute_mean_embedding(another_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f22efe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[3.535534 , 4.9497476, 2.1213202]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that this is correct. \n",
    "# The first review contains 2 words (the last token is a zero vector, which represents the <pad> token). \n",
    "# Let's compute the mean embedding for these 2 words, and multiply the result by the square root of 2:\n",
    "\n",
    "tf.reduce_mean(another_example[0:1, :2], axis=1) * tf.sqrt(2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "862f08dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[6., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check the second review, which contains just one word (we ignore the two padding tokens):\n",
    "\n",
    "tf.reduce_mean(another_example[1:2, :1], axis=1) * tf.sqrt(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61b380d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're ready to train our final model. \n",
    "\n",
    "embedding_size = 20\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "text_vectorization = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=max_tokens, output_mode=\"int\")\n",
    "\n",
    "text_vectorization.adapt(sample_reviews)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    text_vectorization,\n",
    "    tf.keras.layers.Embedding(input_dim=max_tokens,\n",
    "                              output_dim=embedding_size,\n",
    "                              mask_zero=True),  # <pad> tokens => zero vectors\n",
    "    tf.keras.layers.Lambda(compute_mean_embedding),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7dcb53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 10s 9ms/step - loss: 0.4818 - accuracy: 0.7597 - val_loss: 0.3680 - val_accuracy: 0.8402\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 9s 9ms/step - loss: 0.3435 - accuracy: 0.8530 - val_loss: 0.3442 - val_accuracy: 0.8485\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 10s 10ms/step - loss: 0.3252 - accuracy: 0.8623 - val_loss: 0.3302 - val_accuracy: 0.8577\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 9s 9ms/step - loss: 0.3173 - accuracy: 0.8632 - val_loss: 0.3255 - val_accuracy: 0.8562\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 10s 9ms/step - loss: 0.3087 - accuracy: 0.8676 - val_loss: 0.5471 - val_accuracy: 0.7812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x294ff1b7b20>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model and see what accuracy you get. \n",
    "# Try to optimize your pipelines to make training as fast as possible.\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_set, epochs=5, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "34aa935a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\tu'tu\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bed0caa2a04a179ead2359017ed51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f0a267b77343b2a9e259a80cfb5ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\tu'tu\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete9AP4Y6\\imdb_reviews-train…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\tu'tu\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete9AP4Y6\\imdb_reviews-test.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\tu'tu\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete9AP4Y6\\imdb_reviews-unsup…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\tu'tu\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "tf.Tensor(b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\", shape=(), dtype=string)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# Use TFDS to load the same dataset more easily\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets = tfds.load(name=\"imdb_reviews\")\n",
    "train_set, test_set = datasets[\"train\"], datasets[\"test\"]\n",
    "\n",
    "for example in train_set.take(1):\n",
    "    print(example[\"text\"])\n",
    "    print(example[\"label\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
