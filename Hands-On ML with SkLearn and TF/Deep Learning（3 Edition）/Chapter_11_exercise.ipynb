{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a935cd3",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99021654",
   "metadata": {},
   "source": [
    "Glorot初始化和He初始化所要解决的问题是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd0d51",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "Glorot初始化和He初始化被设计为至少在训练开始时使输出标准偏差尽可能接近输入标准偏差。这减少了消失/爆炸梯度的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232fda33",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850e32e",
   "metadata": {},
   "source": [
    "是否可以将所有的权重初始化为相同的值，只要该值是使用 He 初始化随机选择的？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5031896f",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "不可以，所有权重应单独取样；它们不应该都具有相同的初始值。随机采样权重的一个重要目标是打破对称性：如果所有权重都具有相同的初始值，即使该值不为零，那么对称性不会被打破（即，给定层中的所有神经元都是等价的），反向传播将无法打破对称性。具体地说，这意味着任何给定层中所有神经元都将始终具有相同的权重。这就像每层只有一个神经元，而且速度要慢得多。这样的配置几乎不可能收敛到一个好的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395af7f",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bc187",
   "metadata": {},
   "source": [
    "可以将偏差项初始化为0吗？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4adcf0",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "将偏置项初始化为零是非常好的。有些人喜欢像权重一样初始化它们，这也没问题；这没有多大区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1ae27",
   "metadata": {},
   "source": [
    "## Exerice 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef1854",
   "metadata": {},
   "source": [
    "在哪种情况下，您希望使用我们在本章中讨论的每个激活函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10017c5f",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "ReLU通常是隐藏层的良好默认值，因为它速度快，效果好。在某些情况下，其精确输出零的能力也很有用（例如，参见第17章）。此外，它有时可以从优化的实现以及硬件加速中受益。与ReLU相比，ReLU的leaky ReLU变体可以提高模型的质量，而不会过多地阻碍其速度。对于大型神经网络和更复杂的问题，GLU、Swish和Mish可以为您提供质量稍高的模型，但它们有计算成本。双曲正切（tanh）在输出层中非常有用，如果您需要输出固定范围内的数字（默认值在-1和1之间），但现在它在隐藏层中不常用，除非在递归网络中。当您需要估计概率（例如，用于二进制分类）时，S形激活函数在输出层也很有用，但它很少用于隐藏层（例如，对于变分自动编码器的编码层，有例外；参见第17章）。当您需要确保输出始终为正时，softplus激活功能在输出层中非常有用。softmax激活函数在输出层中用于估计互斥类的概率，但在隐藏层中很少使用（如果有的话）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59cef00",
   "metadata": {},
   "source": [
    "## Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf2606",
   "metadata": {},
   "source": [
    "当你使用SGD优化器时，如果你将动量超参数设置得太接近1（例如，0.99999），会发生什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323eff4",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "如果在使用SGD优化器时将动量超参数设置得太接近1（例如，0.99999），那么算法可能会加快速度，希望大致向全局最小值移动，但其动量将使其刚好超过最小值。然后它会减速并返回，再次加速，再次超调，等等。在收敛之前，它可能会以这种方式振荡多次，因此总的来说，与较小动量值相比，收敛所需的时间要长得多。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc98da8",
   "metadata": {},
   "source": [
    "## Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd769ef8",
   "metadata": {},
   "source": [
    "列出可以生成稀疏模型的三种方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa69126",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "生成稀疏模型（即，大多数权重等于零）的一种方法是正常训练模型，然后将极小的权重归零。要获得更多稀疏性，可以应用 $ℓ_1$ 训练期间的正则化，这将优化器推向稀疏。第三种选择是使用TensorFlow模型优化工具包。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d161ba6e",
   "metadata": {},
   "source": [
    "## Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b4910",
   "metadata": {},
   "source": [
    "辍学生会减慢训练的速度吗？它是否减缓推理（例如，对新实例做出预测）？那MC dropout呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5439f256",
   "metadata": {},
   "source": [
    "**答案**：\n",
    "\n",
    "是的，dropout确实会减慢训练速度，一般来说大约是2倍。然而，它对推理速度没有影响，因为它只在训练期间打开。MCdropout与训练期间的dropout完全相同，但在推理过程中它仍然活跃，因此每次推理都会稍微放慢。更重要的是，当使用MC Dropout时，您通常希望运行10次或更多次推断以获得更好的预测。这意味着做出预测的速度会减慢10倍或更多。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fd630",
   "metadata": {},
   "source": [
    "## Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fd1685",
   "metadata": {},
   "source": [
    "在CIFAR10图像数据集上练习训练深度神经网络：\n",
    "\n",
    "1. 构建一个包含20个隐藏层的100个神经元的DNN（这太多了，但这是这个练习的重点）。使用He初始化和Swish激活函数。\n",
    "2. 利用Nadam优化和早期停止，在CIFAR10数据集上对网络进行训练。您可以使用tf.keras.datasets.cifar10.load_ data()来加载它。数据集由60,000个32 ×32像素彩色图像（50000用于训练，10000用于测试）和10个类组成，所以你需要一个包含10个神经元的softmax输出层。请记住，每次更改模型的架构或超参数时，都要搜索正确的学习速率。\n",
    "3. 现在尝试添加批处理归一化并比较学习曲线：它的收敛速度比以前快了吗？它能产生一个更好的模型吗？它会如何影响训练速度呢？\n",
    "4. 尝试用SELU替换批标准化，并进行必要的调整，确保网络自规范化（即标准化输入功能，使用LeCun正常初始化，确保DNN只包含一系列密集层，等）。\n",
    "5. 尝试用alpha dropout来正则化模型。然后，在不重新训练你的模型的情况下，看看你是否可以使用MC dropout来获得更好的准确性。\n",
    "6. 使用1cycle调度重新训练你的模型，看看它是否提高了训练速度和模型精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6bfbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from time import strftime\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6329d11",
   "metadata": {},
   "source": [
    "### 8.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a3b5ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,activation=\"swish\",\n",
    "                                    kernel_initializer=\"he_normal\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c23ff5",
   "metadata": {},
   "source": [
    "### 8.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0540e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the output layer to the model:\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebddecaa",
   "metadata": {},
   "source": [
    "让我们使用学习率为5e-5的Nadam优化器。我尝试了1e-5、3e-5、1e-4、3e-4、1e-3、3e-3和1e-2的学习率，并比较了各自10个时期的学习曲线（使用下面的TensorBoard回调）。3e-5和1e-4的学习率相当不错，所以我尝试了5e-5，结果稍微好一点。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bce17b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-5)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e012c505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 65s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load the CIFAR10 dataset\n",
    "\n",
    "cifar10 = tf.keras.datasets.cifar10.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = cifar10\n",
    "\n",
    "X_train = X_train_full[5000:]\n",
    "y_train = y_train_full[5000:]\n",
    "X_valid = X_train_full[:5000]\n",
    "y_valid = y_train_full[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b21260aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the callbacks we need and train the model\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_model\",\n",
    "                                                         save_best_only=True)\n",
    "\n",
    "run_index = 1 # increment every time you train the model\n",
    "\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_{run_index:03d}\"\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a17f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-2c4967c5a62db935\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-2c4967c5a62db935\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_cifar10_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f088b5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 4.5069 - accuracy: 0.1447INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 15s 9ms/step - loss: 4.4966 - accuracy: 0.1450 - val_loss: 2.1814 - val_accuracy: 0.2132\n",
      "Epoch 2/100\n",
      "1407/1407 [==============================] - 9s 7ms/step - loss: 2.0899 - accuracy: 0.2296 - val_loss: 2.3673 - val_accuracy: 0.1808\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.9683 - accuracy: 0.2745INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.9683 - accuracy: 0.2745 - val_loss: 2.0644 - val_accuracy: 0.2576\n",
      "Epoch 4/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.8869 - accuracy: 0.3079INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8869 - accuracy: 0.3079 - val_loss: 1.8561 - val_accuracy: 0.3216\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.8235 - accuracy: 0.3296INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.8235 - accuracy: 0.3296 - val_loss: 1.8161 - val_accuracy: 0.3418\n",
      "Epoch 6/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.7760 - accuracy: 0.3529INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7758 - accuracy: 0.3531 - val_loss: 1.7659 - val_accuracy: 0.3640\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.7308 - accuracy: 0.3729INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.7308 - accuracy: 0.3729 - val_loss: 1.7393 - val_accuracy: 0.3594\n",
      "Epoch 8/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6952 - accuracy: 0.3913INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6952 - accuracy: 0.3913 - val_loss: 1.6996 - val_accuracy: 0.3930\n",
      "Epoch 9/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.6597 - accuracy: 0.4042INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6596 - accuracy: 0.4044 - val_loss: 1.6618 - val_accuracy: 0.4052\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6314 - accuracy: 0.4133 - val_loss: 1.7114 - val_accuracy: 0.3758\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.6043 - accuracy: 0.4258 - val_loss: 1.6912 - val_accuracy: 0.3870\n",
      "Epoch 12/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.5798 - accuracy: 0.4338INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5796 - accuracy: 0.4339 - val_loss: 1.6257 - val_accuracy: 0.4102\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.5605 - accuracy: 0.4405 - val_loss: 1.6300 - val_accuracy: 0.4196\n",
      "Epoch 14/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.5453 - accuracy: 0.4459INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5453 - accuracy: 0.4459 - val_loss: 1.5948 - val_accuracy: 0.4202\n",
      "Epoch 15/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.5249 - accuracy: 0.4538INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5250 - accuracy: 0.4538 - val_loss: 1.5681 - val_accuracy: 0.4408\n",
      "Epoch 16/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.5065 - accuracy: 0.4611INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.5066 - accuracy: 0.4610 - val_loss: 1.5648 - val_accuracy: 0.4422\n",
      "Epoch 17/100\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 1.4910 - accuracy: 0.4658INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4912 - accuracy: 0.4658 - val_loss: 1.5417 - val_accuracy: 0.4380\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4752 - accuracy: 0.4716 - val_loss: 1.5858 - val_accuracy: 0.4364\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4624 - accuracy: 0.4779 - val_loss: 1.5496 - val_accuracy: 0.4492\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4478 - accuracy: 0.4800 - val_loss: 1.5572 - val_accuracy: 0.4442\n",
      "Epoch 21/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.4369 - accuracy: 0.4857INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4371 - accuracy: 0.4856 - val_loss: 1.5394 - val_accuracy: 0.4462\n",
      "Epoch 22/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.4254 - accuracy: 0.4920INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4255 - accuracy: 0.4920 - val_loss: 1.5204 - val_accuracy: 0.4600\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4128 - accuracy: 0.4957 - val_loss: 1.5315 - val_accuracy: 0.4524\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.4017 - accuracy: 0.4957 - val_loss: 1.5572 - val_accuracy: 0.4390\n",
      "Epoch 25/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3893 - accuracy: 0.5007INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3893 - accuracy: 0.5008 - val_loss: 1.5085 - val_accuracy: 0.4638\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3769 - accuracy: 0.5054 - val_loss: 1.5472 - val_accuracy: 0.4524\n",
      "Epoch 27/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3669 - accuracy: 0.5106INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3669 - accuracy: 0.5106 - val_loss: 1.4853 - val_accuracy: 0.4700\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3561 - accuracy: 0.5166 - val_loss: 1.5107 - val_accuracy: 0.4550\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3519 - accuracy: 0.5138 - val_loss: 1.4922 - val_accuracy: 0.4742\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3365 - accuracy: 0.5176 - val_loss: 1.5701 - val_accuracy: 0.4538\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3291 - accuracy: 0.5234 - val_loss: 1.4900 - val_accuracy: 0.4728\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.3199 - accuracy: 0.5257INFO:tensorflow:Assets written to: my_cifar10_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3199 - accuracy: 0.5257 - val_loss: 1.4817 - val_accuracy: 0.4840\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.3104 - accuracy: 0.5279 - val_loss: 1.5388 - val_accuracy: 0.4668\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2994 - accuracy: 0.5321 - val_loss: 1.5463 - val_accuracy: 0.4618\n",
      "Epoch 35/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2970 - accuracy: 0.5344 - val_loss: 1.5056 - val_accuracy: 0.4732\n",
      "Epoch 36/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2881 - accuracy: 0.5381 - val_loss: 1.4993 - val_accuracy: 0.4704\n",
      "Epoch 37/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2792 - accuracy: 0.5406 - val_loss: 1.4998 - val_accuracy: 0.4884\n",
      "Epoch 38/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2684 - accuracy: 0.5457 - val_loss: 1.4970 - val_accuracy: 0.4684\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2610 - accuracy: 0.5477 - val_loss: 1.4943 - val_accuracy: 0.4760\n",
      "Epoch 40/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2542 - accuracy: 0.5485 - val_loss: 1.5132 - val_accuracy: 0.4640\n",
      "Epoch 41/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2475 - accuracy: 0.5504 - val_loss: 1.4972 - val_accuracy: 0.4802\n",
      "Epoch 42/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2371 - accuracy: 0.5550 - val_loss: 1.5273 - val_accuracy: 0.4726\n",
      "Epoch 43/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2322 - accuracy: 0.5561 - val_loss: 1.5460 - val_accuracy: 0.4680\n",
      "Epoch 44/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2262 - accuracy: 0.5595 - val_loss: 1.5675 - val_accuracy: 0.4596\n",
      "Epoch 45/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2183 - accuracy: 0.5634 - val_loss: 1.5325 - val_accuracy: 0.4716\n",
      "Epoch 46/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2102 - accuracy: 0.5633 - val_loss: 1.5001 - val_accuracy: 0.4804\n",
      "Epoch 47/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1987 - accuracy: 0.5701 - val_loss: 1.5032 - val_accuracy: 0.4786\n",
      "Epoch 48/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1951 - accuracy: 0.5696 - val_loss: 1.5194 - val_accuracy: 0.4690\n",
      "Epoch 49/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1872 - accuracy: 0.5745 - val_loss: 1.5661 - val_accuracy: 0.4628\n",
      "Epoch 50/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1814 - accuracy: 0.5768 - val_loss: 1.5048 - val_accuracy: 0.4784\n",
      "Epoch 51/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1718 - accuracy: 0.5787 - val_loss: 1.5201 - val_accuracy: 0.4788\n",
      "Epoch 52/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.1668 - accuracy: 0.5803 - val_loss: 1.5369 - val_accuracy: 0.4602\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1783a861400>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c447e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4817 - accuracy: 0.4840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4817038774490356, 0.48399999737739563]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18be9780",
   "metadata": {},
   "source": [
    "验证损失最小的模型在验证集上的准确度约为46.8%。它花费了29个时期达到最低的验证丢失，在我的笔记本电脑（没有GPU）上每个时期大约10秒。让我们看看是否可以使用批处理规范化来改进模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0878a44",
   "metadata": {},
   "source": [
    "### 8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aadaf3",
   "metadata": {},
   "source": [
    "下面的代码与上面的代码非常相似，只做了一些更改：\n",
    "\n",
    "1. 我在每个密集层之后（激活功能之前）添加了BN层，除了输出层。\n",
    "2. 我将学习率改为5e-4。我用1e-5、3e-5、5e-5、1e-4、3e-4、5e-4、1e-3和3e-3进行了实验，我选择了20个时期后验证性能最好的一个。\n",
    "3. 我将运行目录重命名为run_bn_*，将模型文件名重命名为my_cifar10_bn_mode。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f896875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 2.0331 - accuracy: 0.2619INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 29s 16ms/step - loss: 2.0329 - accuracy: 0.2620 - val_loss: 1.8883 - val_accuracy: 0.3350\n",
      "Epoch 2/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.7749 - accuracy: 0.3628INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.7747 - accuracy: 0.3628 - val_loss: 1.7966 - val_accuracy: 0.3562\n",
      "Epoch 3/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.6731 - accuracy: 0.4052INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 22s 15ms/step - loss: 1.6731 - accuracy: 0.4054 - val_loss: 1.7831 - val_accuracy: 0.3686\n",
      "Epoch 4/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.6049 - accuracy: 0.4265INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.6049 - accuracy: 0.4265 - val_loss: 1.6593 - val_accuracy: 0.4116\n",
      "Epoch 5/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.5463 - accuracy: 0.4493INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.5463 - accuracy: 0.4493 - val_loss: 1.6295 - val_accuracy: 0.4292\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.5001 - accuracy: 0.4699 - val_loss: 1.8032 - val_accuracy: 0.3732\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.4546 - accuracy: 0.4844 - val_loss: 1.6868 - val_accuracy: 0.4172\n",
      "Epoch 8/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.4156 - accuracy: 0.4980INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.4156 - accuracy: 0.4980 - val_loss: 1.5918 - val_accuracy: 0.4430\n",
      "Epoch 9/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3848 - accuracy: 0.5106INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3847 - accuracy: 0.5106 - val_loss: 1.5285 - val_accuracy: 0.4546\n",
      "Epoch 10/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.3548 - accuracy: 0.5233INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3550 - accuracy: 0.5232 - val_loss: 1.4800 - val_accuracy: 0.4656\n",
      "Epoch 11/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.3282 - accuracy: 0.5298INFO:tensorflow:Assets written to: my_cifar10_bn_model\\assets\n",
      "1407/1407 [==============================] - 21s 15ms/step - loss: 1.3281 - accuracy: 0.5298 - val_loss: 1.4449 - val_accuracy: 0.4844\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2986 - accuracy: 0.5392 - val_loss: 1.5180 - val_accuracy: 0.4614\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2724 - accuracy: 0.5495 - val_loss: 1.5796 - val_accuracy: 0.4458\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2475 - accuracy: 0.5575 - val_loss: 1.4996 - val_accuracy: 0.4778\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2279 - accuracy: 0.5675 - val_loss: 1.8289 - val_accuracy: 0.4158\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2079 - accuracy: 0.5737 - val_loss: 1.4688 - val_accuracy: 0.4888\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1909 - accuracy: 0.5786 - val_loss: 1.4732 - val_accuracy: 0.4964\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1666 - accuracy: 0.5860 - val_loss: 1.5374 - val_accuracy: 0.4696\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1496 - accuracy: 0.5941 - val_loss: 1.5607 - val_accuracy: 0.4742\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1330 - accuracy: 0.6022 - val_loss: 1.5536 - val_accuracy: 0.4666\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1151 - accuracy: 0.6060 - val_loss: 1.6986 - val_accuracy: 0.4246\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1017 - accuracy: 0.6110 - val_loss: 1.6077 - val_accuracy: 0.4750\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0892 - accuracy: 0.6173 - val_loss: 1.5339 - val_accuracy: 0.4778\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0686 - accuracy: 0.6235 - val_loss: 1.5180 - val_accuracy: 0.4866\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0574 - accuracy: 0.6266 - val_loss: 1.6930 - val_accuracy: 0.4360\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0429 - accuracy: 0.6326 - val_loss: 1.4493 - val_accuracy: 0.5016\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0307 - accuracy: 0.6365 - val_loss: 1.4688 - val_accuracy: 0.5090\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0179 - accuracy: 0.6395 - val_loss: 1.7259 - val_accuracy: 0.4512\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0076 - accuracy: 0.6476 - val_loss: 1.4642 - val_accuracy: 0.4978\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9960 - accuracy: 0.6459 - val_loss: 1.5535 - val_accuracy: 0.4802\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9803 - accuracy: 0.6531 - val_loss: 1.5549 - val_accuracy: 0.4934\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 1.4449 - accuracy: 0.4844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.444880723953247, 0.4844000041484833]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100, kernel_initializer=\"he_normal\"))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Activation(\"swish\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_cifar10_bn_model\",\n",
    "                                                         save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_bn_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100,\n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22b61ff",
   "metadata": {},
   "source": [
    "**模型收敛速度是否比以前更快？**\n",
    "\n",
    "快得多！前一个模型花费了29个时期达到最低的验证损失，而新模型仅在12个时期内实现了相同的损失，并继续取得进展，直到第17个时期。BN层稳定了训练，允许我们使用更大的学习率，因此收敛速度更快。\n",
    "\n",
    "**BN是否生产出更好的模型？**\n",
    "\n",
    "对最终的模型也要好得多，验证准确率为50.7%，而不是46.7%。它仍然不是一个很好的模型，但至少比以前好得多（卷积神经网络会做得更好，但这是一个不同的主题，见第14章）。\n",
    "\n",
    "**BN如何影响训练速度？**\n",
    "\n",
    "尽管模型收敛得更快，但由于BN层需要额外的计算，每个历元大约需要20秒而不是10秒。但总体而言，达到最佳模型的训练时间（壁时间）缩短了约10%。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028b262",
   "metadata": {},
   "source": [
    "### 8.4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "118dbdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.9215 - accuracy: 0.3103INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.9210 - accuracy: 0.3105 - val_loss: 1.8195 - val_accuracy: 0.3500\n",
      "Epoch 2/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.7063 - accuracy: 0.3918INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7062 - accuracy: 0.3918 - val_loss: 1.6988 - val_accuracy: 0.3978\n",
      "Epoch 3/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.6101 - accuracy: 0.4315INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.6101 - accuracy: 0.4315 - val_loss: 1.6472 - val_accuracy: 0.4074\n",
      "Epoch 4/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5429 - accuracy: 0.4559 - val_loss: 1.6516 - val_accuracy: 0.4290\n",
      "Epoch 5/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.4831 - accuracy: 0.4807INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.4831 - accuracy: 0.4807 - val_loss: 1.5880 - val_accuracy: 0.4468\n",
      "Epoch 6/100\n",
      "1405/1407 [============================>.] - ETA: 0s - loss: 1.4361 - accuracy: 0.4952INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.4363 - accuracy: 0.4951 - val_loss: 1.5195 - val_accuracy: 0.4646\n",
      "Epoch 7/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.3936 - accuracy: 0.5130 - val_loss: 1.5357 - val_accuracy: 0.4658\n",
      "Epoch 8/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.3521 - accuracy: 0.5260INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.3517 - accuracy: 0.5262 - val_loss: 1.5055 - val_accuracy: 0.4762\n",
      "Epoch 9/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.3200 - accuracy: 0.5404INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 12s 8ms/step - loss: 1.3199 - accuracy: 0.5404 - val_loss: 1.4854 - val_accuracy: 0.4724\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.2882 - accuracy: 0.5530 - val_loss: 1.5002 - val_accuracy: 0.4842\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2565 - accuracy: 0.5678 - val_loss: 1.5196 - val_accuracy: 0.4880\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2346 - accuracy: 0.5756 - val_loss: 1.4986 - val_accuracy: 0.4944\n",
      "Epoch 13/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.2103 - accuracy: 0.5812INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.2102 - accuracy: 0.5812 - val_loss: 1.4701 - val_accuracy: 0.5060\n",
      "Epoch 14/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.1848 - accuracy: 0.5927 - val_loss: 1.4937 - val_accuracy: 0.5036\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1622 - accuracy: 0.6003 - val_loss: 1.5035 - val_accuracy: 0.4956\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1375 - accuracy: 0.6086 - val_loss: 1.5110 - val_accuracy: 0.4992\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.1109 - accuracy: 0.6171 - val_loss: 1.5429 - val_accuracy: 0.4976\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.5025 - accuracy: 0.5964 - val_loss: 1.6042 - val_accuracy: 0.4456\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.2667 - accuracy: 0.5574 - val_loss: 1.5147 - val_accuracy: 0.4944\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1743 - accuracy: 0.5900 - val_loss: 1.5047 - val_accuracy: 0.4930\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.1290 - accuracy: 0.6054 - val_loss: 1.5106 - val_accuracy: 0.5070\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0922 - accuracy: 0.6213 - val_loss: 1.5213 - val_accuracy: 0.5044\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 10s 7ms/step - loss: 1.0662 - accuracy: 0.6331 - val_loss: 1.5026 - val_accuracy: 0.4992\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0444 - accuracy: 0.6396 - val_loss: 1.5463 - val_accuracy: 0.5016\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 11s 7ms/step - loss: 1.0266 - accuracy: 0.6490 - val_loss: 1.5375 - val_accuracy: 0.5086\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 1.0093 - accuracy: 0.6535 - val_loss: 1.5551 - val_accuracy: 0.5036\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9944 - accuracy: 0.6602 - val_loss: 1.5460 - val_accuracy: 0.5086\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9868 - accuracy: 0.6645 - val_loss: 1.5868 - val_accuracy: 0.4986\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9837 - accuracy: 0.6641 - val_loss: 1.6124 - val_accuracy: 0.5006\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9734 - accuracy: 0.6678 - val_loss: 1.5607 - val_accuracy: 0.5086\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9676 - accuracy: 0.6705 - val_loss: 1.5528 - val_accuracy: 0.5136\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9650 - accuracy: 0.6725 - val_loss: 1.5849 - val_accuracy: 0.5106\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 11s 8ms/step - loss: 0.9457 - accuracy: 0.6795 - val_loss: 1.6060 - val_accuracy: 0.5078\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4701 - accuracy: 0.5060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4701128005981445, 0.5059999823570251]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_selu_model\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_selu_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e4791",
   "metadata": {},
   "source": [
    "### 8.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93635a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1401/1407 [============================>.] - ETA: 0s - loss: 1.9416 - accuracy: 0.3058INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 15s 9ms/step - loss: 1.9409 - accuracy: 0.3061 - val_loss: 1.8503 - val_accuracy: 0.3380\n",
      "Epoch 2/100\n",
      "1400/1407 [============================>.] - ETA: 0s - loss: 1.7156 - accuracy: 0.3937INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 12s 9ms/step - loss: 1.7156 - accuracy: 0.3936 - val_loss: 1.7217 - val_accuracy: 0.3888\n",
      "Epoch 3/100\n",
      "1404/1407 [============================>.] - ETA: 0s - loss: 1.6165 - accuracy: 0.4314INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 13s 9ms/step - loss: 1.6163 - accuracy: 0.4316 - val_loss: 1.6346 - val_accuracy: 0.4148\n",
      "Epoch 4/100\n",
      "1402/1407 [============================>.] - ETA: 0s - loss: 1.5486 - accuracy: 0.4590INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.5489 - accuracy: 0.4590 - val_loss: 1.6141 - val_accuracy: 0.4374\n",
      "Epoch 5/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.4910 - accuracy: 0.4809INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.4910 - accuracy: 0.4809 - val_loss: 1.5595 - val_accuracy: 0.4500\n",
      "Epoch 6/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.4496 - accuracy: 0.4951INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.4496 - accuracy: 0.4951 - val_loss: 1.5365 - val_accuracy: 0.4686\n",
      "Epoch 7/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.4057 - accuracy: 0.5059INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 17s 12ms/step - loss: 1.4057 - accuracy: 0.5059 - val_loss: 1.5159 - val_accuracy: 0.4676\n",
      "Epoch 8/100\n",
      "1406/1407 [============================>.] - ETA: 0s - loss: 1.3604 - accuracy: 0.5263INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.3605 - accuracy: 0.5263 - val_loss: 1.4854 - val_accuracy: 0.4850\n",
      "Epoch 9/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3327 - accuracy: 0.5373 - val_loss: 1.5233 - val_accuracy: 0.4758\n",
      "Epoch 10/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2979 - accuracy: 0.5494 - val_loss: 1.5711 - val_accuracy: 0.4760\n",
      "Epoch 11/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2718 - accuracy: 0.5574 - val_loss: 1.5028 - val_accuracy: 0.4970\n",
      "Epoch 12/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2359 - accuracy: 0.5724 - val_loss: 1.4909 - val_accuracy: 0.4894\n",
      "Epoch 13/100\n",
      "1407/1407 [==============================] - ETA: 0s - loss: 1.2131 - accuracy: 0.5832INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 16s 11ms/step - loss: 1.2131 - accuracy: 0.5832 - val_loss: 1.4842 - val_accuracy: 0.4994\n",
      "Epoch 14/100\n",
      "1403/1407 [============================>.] - ETA: 0s - loss: 1.1889 - accuracy: 0.5891INFO:tensorflow:Assets written to: my_cifar10_selu_model\\assets\n",
      "1407/1407 [==============================] - 16s 12ms/step - loss: 1.1887 - accuracy: 0.5893 - val_loss: 1.4600 - val_accuracy: 0.5078\n",
      "Epoch 15/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1692 - accuracy: 0.5980 - val_loss: 1.5186 - val_accuracy: 0.5004\n",
      "Epoch 16/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.2189 - accuracy: 0.5920 - val_loss: 1.6896 - val_accuracy: 0.4166\n",
      "Epoch 17/100\n",
      "1407/1407 [==============================] - 15s 10ms/step - loss: 1.3732 - accuracy: 0.5164 - val_loss: 1.5307 - val_accuracy: 0.4706\n",
      "Epoch 18/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.2418 - accuracy: 0.5678 - val_loss: 1.5000 - val_accuracy: 0.4924\n",
      "Epoch 19/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1787 - accuracy: 0.5908 - val_loss: 1.4942 - val_accuracy: 0.4946\n",
      "Epoch 20/100\n",
      "1407/1407 [==============================] - 15s 11ms/step - loss: 1.1385 - accuracy: 0.6074 - val_loss: 1.5281 - val_accuracy: 0.4940\n",
      "Epoch 21/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.1041 - accuracy: 0.6188 - val_loss: 1.4871 - val_accuracy: 0.5134\n",
      "Epoch 22/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0830 - accuracy: 0.6305 - val_loss: 1.4866 - val_accuracy: 0.5208\n",
      "Epoch 23/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0632 - accuracy: 0.6369 - val_loss: 1.5162 - val_accuracy: 0.5112\n",
      "Epoch 24/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0519 - accuracy: 0.6410 - val_loss: 1.4900 - val_accuracy: 0.5158\n",
      "Epoch 25/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0477 - accuracy: 0.6426 - val_loss: 1.5088 - val_accuracy: 0.5186\n",
      "Epoch 26/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0316 - accuracy: 0.6490 - val_loss: 1.5076 - val_accuracy: 0.5124\n",
      "Epoch 27/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 1.0107 - accuracy: 0.6567 - val_loss: 1.5252 - val_accuracy: 0.5120\n",
      "Epoch 28/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9956 - accuracy: 0.6642 - val_loss: 1.5267 - val_accuracy: 0.5112\n",
      "Epoch 29/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9836 - accuracy: 0.6676 - val_loss: 1.5865 - val_accuracy: 0.5180\n",
      "Epoch 30/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9561 - accuracy: 0.6785 - val_loss: 1.5166 - val_accuracy: 0.5198\n",
      "Epoch 31/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9452 - accuracy: 0.6801 - val_loss: 1.5474 - val_accuracy: 0.5160\n",
      "Epoch 32/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9454 - accuracy: 0.6820 - val_loss: 1.6213 - val_accuracy: 0.5114\n",
      "Epoch 33/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9155 - accuracy: 0.6943 - val_loss: 1.5579 - val_accuracy: 0.5164\n",
      "Epoch 34/100\n",
      "1407/1407 [==============================] - 14s 10ms/step - loss: 0.9023 - accuracy: 0.6993 - val_loss: 1.6489 - val_accuracy: 0.5146\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.4600 - accuracy: 0.5078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.459976315498352, 0.5077999830245972]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=7e-4)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=20, restore_best_weights=True)\n",
    "model_checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"my_cifar10_selu_model\", save_best_only=True)\n",
    "run_index = 1 # increment every time you train the model\n",
    "run_logdir = Path() / \"my_cifar10_logs\" / f\"run_selu_{run_index:03d}\"\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "callbacks = [early_stopping_cb, model_checkpoint_cb, tensorboard_cb]\n",
    "\n",
    "X_means = X_train.mean(axis=0)\n",
    "X_stds = X_train.std(axis=0)\n",
    "X_train_scaled = (X_train - X_means) / X_stds\n",
    "X_valid_scaled = (X_valid - X_means) / X_stds\n",
    "X_test_scaled = (X_test - X_means) / X_stds\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=100,\n",
    "          validation_data=(X_valid_scaled, y_valid),\n",
    "          callbacks=callbacks)\n",
    "\n",
    "model.evaluate(X_valid_scaled, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2342bd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 3ms/step\n",
      "157/157 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5078"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MCAlphaDropout(tf.keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)\n",
    "    \n",
    "mc_model = tf.keras.Sequential([\n",
    "    (\n",
    "        MCAlphaDropout(layer.rate)\n",
    "        if isinstance(layer, tf.keras.layers.AlphaDropout)\n",
    "        else layer\n",
    "    )\n",
    "    for layer in model.layers\n",
    "])\n",
    "\n",
    "# The first will run the model many times (10 by default) and it will return the mean predicted class probabilities.\n",
    "def mc_dropout_predict_probas(mc_model, X, n_samples=10):\n",
    "    Y_probas = [mc_model.predict(X) for sample in range(n_samples)]\n",
    "    return np.mean(Y_probas, axis=0)\n",
    "\n",
    "# The second will use these mean probabilities to predict the most likely class for each instance.\n",
    "def mc_dropout_predict_classes(mc_model, X, n_samples=10):\n",
    "    Y_probas = mc_dropout_predict_probas(mc_model, X, n_samples)\n",
    "    return Y_probas.argmax(axis=1)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "y_pred = mc_dropout_predict_classes(mc_model, X_valid_scaled)\n",
    "accuracy = (y_pred == y_valid[:, 0]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771574f3",
   "metadata": {},
   "source": [
    "### 8.6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca9814e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'find_learning_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m               optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     16\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     18\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m---> 19\u001b[0m rates, losses \u001b[38;5;241m=\u001b[39m \u001b[43mfind_learning_rate\u001b[49m(model, X_train_scaled, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     20\u001b[0m                                    batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[0;32m     21\u001b[0m plot_lr_vs_loss(rates, losses)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'find_learning_rate' is not defined"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                    kernel_initializer=\"lecun_normal\",\n",
    "                                    activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "batch_size = 128\n",
    "rates, losses = find_learning_rate(model, X_train_scaled, y_train, epochs=1,\n",
    "                                   batch_size=batch_size)\n",
    "plot_lr_vs_loss(rates, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754e0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=[32, 32, 3]))\n",
    "for _ in range(20):\n",
    "    model.add(tf.keras.layers.Dense(100,\n",
    "                                 kernel_initializer=\"lecun_normal\",\n",
    "                                 activation=\"selu\"))\n",
    "\n",
    "model.add(tf.keras.layers.AlphaDropout(rate=0.1))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=2e-2)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30048eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "n_iterations = math.ceil(len(X_train_scaled) / batch_size) * n_epochs\n",
    "onecycle = OneCycleScheduler(n_iterations, max_lr=0.05)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, batch_size=batch_size,\n",
    "                    validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[onecycle])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
